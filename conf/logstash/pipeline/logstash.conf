input {
  beats {
    port => 5044
  }
}

filter {
  # Handle Docker JSON wrapper - Docker wraps logs in JSON with "log" field
  if [log] {
    # Extract the actual log message from Docker's JSON wrapper
    if [log] =~ /^\{/ {
      # Parse the JSON log message
      json {
        source => "log"
      }
      
      # Use @timestamp from parsed JSON if available
      if [@timestamp] {
        date {
          match => [ "@timestamp", "ISO8601" ]
        }
      }
      
      # Rename fields for clarity (logstash-logback-encoder uses these field names)
      if [logger_name] {
        mutate {
          rename => { "logger_name" => "logger" }
        }
      }
      
      # Remove the Docker wrapper log field after parsing
      mutate {
        remove_field => [ "log" ]
      }
    } else {
      # Drop non-JSON logs
      drop {}
    }
  } else if [message] =~ /^\{/ {
    # Fallback: if message is directly JSON (not wrapped by Docker)
    json {
      source => "message"
    }
    
    if [@timestamp] {
      date {
        match => [ "@timestamp", "ISO8601" ]
      }
    }
    
    if [logger_name] {
      mutate {
        rename => { "logger_name" => "logger" }
      }
    }
    
    mutate {
      remove_field => [ "message" ]
    }
  } else {
    # Drop non-JSON logs
    drop {}
  }
  
  # Add container metadata from Docker
  if [docker][container][name] {
    mutate {
      add_field => { "container_name" => "%{[docker][container][name]}" }
    }
  }
  
  if [fields][container_name] {
    mutate {
      add_field => { "container_name" => "%{[fields][container_name]}" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "logs-%{+YYYY.MM.dd}"
  }
  stdout {
    codec => rubydebug
  }
}
